{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youtao6256/MVSEP-MDX23-music-separation-model/blob/main/MVSep_MDX23_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqyGdDfyS27b"
      },
      "source": [
        "# MVSep-MDX23 Colab Fork v2.3\n",
        "Adaptation of MVSep-MDX23 algorithm for Colab, with few tweaks:\n",
        "\n",
        "https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb\n",
        "\n",
        "Recent changes:\n",
        "<font size=2>\n",
        "\n",
        "**v2.3**\n",
        "* HQ3-Instr model replaced by VitLarge23 (thanks to MVSep)\n",
        "* Improved MDXv2 processing (thanks to Anjok)\n",
        "* Improved BigShifts algo (v2)\n",
        "* BigShifts processing added to MDXv3 & VitLarge\n",
        "* Faster folder batch processing\n",
        "\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "    <summary>Full changelog :</summary>\n",
        "<br>\n",
        "<font size=2>\n",
        "<br>\n",
        "\n",
        "[**v2.2.2**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/v2.2)\n",
        "* Improved MDXv3 chunking code (thanks to HymnStudio)\n",
        "* D1581 demo model replaced by new InstVocHQ MDXv3 model.\n",
        "<br>\n",
        "\n",
        "**v2.2.1**\n",
        "* Added custom weights feature\n",
        "* Fixed some bugs\n",
        "* Fixed input: you can use a file or a folder as input now\n",
        "<br>\n",
        "\n",
        "**v2.2**\n",
        "* Added MDXv3 compatibility\n",
        "* Added MDXv3 demo model D1581 in vocals stem multiband ensemble.\n",
        "* Added VOC-FT Fullband SRS instead of UVR-MDX-Instr-HQ3.\n",
        "* Added 2stems feature : output only vocals/instrum (faster processing)\n",
        "* Added 16bit output format option\n",
        "* Added \"BigShift trick\" for MDX models\n",
        "* Added separated overlap values for MDX, MDXv3 and Demucs\n",
        "* Fixed volume compensation fine-tuning for MDX-VOC-FT\n",
        "<br>\n",
        "\n",
        "[**v2.1 (by deton24)**](https://github.com/deton24/MVSEP-MDX23-Colab_v2.1)\n",
        "* Updated with MDX-VOC-FT instead of Kim Vocal 2\n",
        "<br>\n",
        "\n",
        "[**v2.0**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/2.0)\n",
        "* Updated with new Kim Vocal 2 & UVR-MDX-Instr-HQ3 models\n",
        "* Folder batch processing\n",
        "* Fixed high frequency bleed in vocals\n",
        "* Fixed volume compensation for MDX models\n",
        "<br>\n",
        "</font>\n",
        "</details>\n",
        "<br>\n",
        "\n",
        "Credits:\n",
        "* [ZFTurbo/MVSep](https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model)\n",
        "* Models by [Demucs](https://github.com/facebookresearch/demucs), [Anjok](https://github.com/Anjok07/ultimatevocalremovergui) & [Kimberley Jensen](https://github.com/KimberleyJensen)\n",
        "* Adaptation & tweaks by [jarredou](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWX5WOqjU0QC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a5eb15-b2be-45ee-dd82-2f0975d7a454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing... This will take 1 minute...\n",
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/MVSEP-MDX23-Colab_v2\n",
            "Installation done !\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Installation\n",
        "#@markdown *Run this cell to install MVSep-MDX23*\n",
        "print('Installing... This will take 1 minute...')\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/jarredou/MVSEP-MDX23-Colab_v2.git &> /dev/null\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "print('Installation done !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-FubqRMS27k"
      },
      "source": [
        "### About settings:\n",
        "\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **BigShifts :** Better quality/speed performance with values between 3 and 11, **BUT** 11 doesn't always give the best results. Think about it like seed, different values will give slightly different results.<br>\n",
        "Higher values = longer processing.\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Overlap InstVoc/VitLarge :** No big advantage to use high values when BigShifts is already high. If you use BigShifts=1 (regular processing), you can use higher values like 8 or even 16.<br>\n",
        "Higher values = longer processing.<br>\n",
        " *Same goes with overlap_VOCFT, but with values between 0 and 0.95*\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Weights :** How much importance the result from the given model will have in final results.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V7n1nXKsU4sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078fe9ee-756f-4c0b-edf8-7f3327145c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MVSEP-MDX23-Colab_v2\n",
            "GPU use: 0\n",
            "started!\n",
            "\n",
            "Options: \n",
            "BigShifts: 8\n",
            "\n",
            "weight_InstVoc: 8.0\n",
            "weight_VitLarge: 5.0\n",
            "\n",
            "overlap_InstVoc: 1\n",
            "overlap_VitLarge: 1\n",
            "\n",
            "use_VOCFT: False\n",
            "vocals_only: True\n",
            "output_format: PCM_16\n",
            "\n",
            "Loading InstVoc into memory\n",
            "100% 427M/427M [00:02<00:00, 162MB/s]\n",
            "100% 709/709 [00:00<00:00, 2.78MB/s]\n",
            "Loading VitLarge into memory\n",
            "100% 824M/824M [00:03<00:00, 287MB/s]\n",
            "100% 1.21k/1.21k [00:00<00:00, 5.72MB/s]\n",
            "model.safetensors: 100% 850M/850M [00:09<00:00, 87.1MB/s]\n",
            "Go for: /content/drive/MyDrive/çª— cut version.mp3\n",
            "Input audio: (2, 9667584) Sample rate: 44100\n",
            "Processing vocals with VitLarge model...\n",
            "100% 8/8 [00:38<00:00,  4.81s/it]\n",
            "Processing vocals with MDXv3 InstVocHQ model...\n",
            "  0% 0/8 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "#@markdown #Separation\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "\n",
        "\n",
        "input = '/content/drive/MyDrive/\\u7A97 cut version.mp3' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/output' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown *Bigshifts=1 to disable that feature*\n",
        "\n",
        "BigShifts = 8 #@param {type:\"slider\", min:1, max:41, step:1}\n",
        "#@markdown ---\n",
        "overlap_InstVoc = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "overlap_VitLarge = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "#@markdown ---\n",
        "weight_InstVoc = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "weight_VitLarge = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "use_VOCFT = False #@param {type:\"boolean\"}\n",
        "overlap_VOCFT = 0.1 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "weight_VOCFT = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "vocals_instru_only = True #@param {type:\"boolean\"}\n",
        "overlap_demucs = 0.6 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "#@markdown ---\n",
        "output_format = 'PCM_16' #@param [\"PCM_16\", \"FLOAT\"]\n",
        "if vocals_instru_only:\n",
        "    vocals_only = '--vocals_only true'\n",
        "else:\n",
        "    vocals_only = ''\n",
        "\n",
        "\n",
        "if use_VOCFT:\n",
        "    use_VOCFT = '--use_VOCFT true'\n",
        "else:\n",
        "    use_VOCFT = ''\n",
        "\n",
        "if Path(input).is_file():\n",
        "  file_path = input\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "        --large_gpu \\\n",
        "        --weight_InstVoc {weight_InstVoc} \\\n",
        "        --weight_VOCFT {weight_VOCFT} \\\n",
        "        --weight_VitLarge {weight_VitLarge} \\\n",
        "        --input_audio \"{file_path}\" \\\n",
        "        --overlap_demucs {overlap_demucs} \\\n",
        "        --overlap_VOCFT {overlap_VOCFT} \\\n",
        "        --overlap_InstVoc {overlap_InstVoc} \\\n",
        "        --overlap_VitLarge {overlap_VitLarge} \\\n",
        "        --output_format {output_format} \\\n",
        "        --BigShifts {BigShifts} \\\n",
        "        --output_folder \"{output_folder}\" \\\n",
        "        {vocals_only} \\\n",
        "        {use_VOCFT}\n",
        "\n",
        "else:\n",
        "  file_paths = sorted([f'\"{glob.escape(path)}\"' for path in glob.glob(input + \"/*\")])[:]\n",
        "  input_audio_args = ' '.join(file_paths)\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "          --large_gpu \\\n",
        "          --weight_InstVoc {weight_InstVoc} \\\n",
        "          --weight_VOCFT {weight_VOCFT} \\\n",
        "          --weight_VitLarge {weight_VitLarge} \\\n",
        "          --input_audio {input_audio_args} \\\n",
        "          --overlap_demucs {overlap_demucs} \\\n",
        "          --overlap_VOCFT {overlap_VOCFT} \\\n",
        "          --overlap_InstVoc {int(overlap_InstVoc)} \\\n",
        "          --overlap_VitLarge {int(overlap_VitLarge)} \\\n",
        "          --output_format {output_format} \\\n",
        "          --BigShifts {BigShifts} \\\n",
        "          --output_folder \"{output_folder}\" \\\n",
        "          {vocals_only} \\\n",
        "          {use_VOCFT}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RsgVzcZm4PI",
        "outputId": "1465f8ac-6dbf-4f9a-8f6b-5ca93a7d5c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
